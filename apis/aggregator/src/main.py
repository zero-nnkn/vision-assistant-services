import base64
from concurrent.futures import ThreadPoolExecutor

import boto3
from aggregator.service import upload_image_to_S3, vqa_pipeline
from config import settings
from fastapi import FastAPI, File, Request, status
from fastapi.exceptions import RequestValidationError
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, RedirectResponse

app = FastAPI(title="Aggregator API")

origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_headers=settings.CORS_HEADERS,
    allow_credentials=True,
    allow_methods=["*"],
)

# Image storage initialization
s3 = boto3.resource(
    "s3",
    aws_access_key_id=settings.AWS_ACCESS_KEY_ID,
    aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,
)


@app.exception_handler(RequestValidationError)
def validation_exception_handler(request: Request, exc: RequestValidationError):
    # Get the original 'detail' list of errors
    details = exc.errors()
    error_details = []

    for error in details:
        error_details.append({"error": error["msg"] + " " + str(error["loc"])})
    return JSONResponse(content={"message": error_details})


@app.get("/", include_in_schema=False)
def root() -> None:
    return RedirectResponse("/docs")


@app.get("/health", status_code=status.HTTP_200_OK, tags=["health"])
def perform_healthcheck() -> None:
    return JSONResponse(content={"message": "success"})


@app.post("/inference")
def aggregate(
    speech: bytes = File(),
    image_file_content: bytes = File(None),
    image_filename: str = "",
) -> None:
    """
    The endpoint that push image to S3, and concurrently invoke other three services
        to process the image, then aggregate outputs and response to the client

    Args:
        speech (bytes): an audio of user's question
        image_file_content (bytes): Optional, image sent by client for asking.
            Each image is sent only once
        image_filename (str): if the image is already saved in S3, client send only its filename,
            the VLM service will query and process it.

    Returns:
        image_filename (str): unique filename of the image in S3 (generated by UUID)
        answer_text (str): answer in text form
        answer_speech (base64): answer in audio form, which is converted from bytes to base64
    """
    if image_filename != "":
        # If image is already saved in S3, client will send only the image_filename,
        # The VLM service will query and process the image .
        try:
            vqa_output = vqa_pipeline(speech=speech, image=image_filename)
        except Exception as err:
            return JSONResponse(status_code=500, content={"message": str(err)})
        else:
            # Convert speech to base64
            base64_speech = base64.b64encode(vqa_output.get("answer_speech")).decode("utf-8")
            return JSONResponse(
                status_code=200,
                content={
                    "image_filename": image_filename,
                    "answer_text": vqa_output.get("answer_text"),
                    "answer_speech": base64_speech,
                },
            )
    else:
        # Else if image is inferred for the first time, client will send the image in the request
        # We need to push the image to S3 for later queries
        bucket_name = settings.BUCKET_NAME
        # Multi-threading: saving + processing image
        executor = ThreadPoolExecutor()
        upload_future = executor.submit(upload_image_to_S3, s3, image_file_content, bucket_name)
        vqa_future = executor.submit(vqa_pipeline, speech, image_file_content)

        try:
            image_filename = upload_future.result()
            vqa_output = vqa_future.result()
        except Exception as err:
            return JSONResponse(status_code=500, content={"message": str(err)})
        else:
            # Convert speech to base64
            base64_speech = base64.b64encode(vqa_output.get("answer_speech")).decode("utf-8")
            return JSONResponse(
                status_code=200,
                content={
                    "image_filename": image_filename,
                    "answer_text": vqa_output.get("answer_text"),
                    "answer_speech": base64_speech,
                },
            )


if __name__ == "__main__":
    import uvicorn

    uvicorn.run("main:app", host=settings.HOST, port=settings.PORT, reload=True)
